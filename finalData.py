import json
import datetime
import ast
import requests
import xmltodict
import collections
import bisect
import os
import isodate
import numpy
from math import floor, ceil
from collections import Counter
import math


APIKEY='API'

def getLengths(codeFile):
    '''Returns a dictionary where keys=video IDs and values=length of video in seconds'''
    code=json.load(open(codeFile))
    v={}
    for i in code.keys():
        information=json.loads(requests.get('https://www.googleapis.com/youtube/v3/videos?part=contentDetails%2Cstatistics&id='+i+'&key='+APIKEY).content)
        if len(information['items'])!=0:
            length=information['items'][0]['contentDetails']['duration']
    	    parsedT=isodate.parse_duration(length)
            secs=parsedT.total_seconds()
            counts=information['items'][0]['statistics']['viewCount']
            v[i]={'length':secs,'counts':counts}
    with open('lengthsAndViews.json', 'w') as outfile:
            json.dump(v, outfile)

#getLengths('videos.json')

def generateVideoDict(fileName):
    '''generates a dictionary where keys are video ids and values are lists of 3-tuples
    (event type, timestamp, current video time). If the events is not play or pause video,
    a 2-tuple is create instead'''
    #(event type,timestamp,current video time,speed) for video events
    filename=json.load(open(fileName))
    video={}
    code=''
    found=False
    current=0
    for i in range(len(filename)):
        if filename[i]['event_type']=='pause_video' or filename[i]['event_type']=='play_video':
            d = json.loads(ast.literal_eval(filename[i]['event']))
            videoDict=dict((k,v) for (k,v) in d.items())
            if code!='' and code!=videoDict['code']:
                video[code].append(('watched another video',datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0)))            
            code=videoDict['code']
            found=True
            try:
                current=float(videoDict['currentTime'])
                if current<0:
                    raise ValueError
            #when currentTime is not there
            except (KeyError, TypeError,ValueError):
                if filename[i]['event_type']=='pause_video' and filename[i-1]['event_type']=='play_video':
                    diff=datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0)-datetime.datetime.utcfromtimestamp(filename[i-1]['timestamp']/1000.0)
                    current+=diff.total_seconds()
                elif filename[i]['event_type']=='play_video' and filename[i-1]['event_type']=='pause_video':
                    current=current
                elif filename[i]['event_type']=='play_video' and filename[i-1]['event_type']=='play_video':
                    diff=datetime.datetime.utcfromtimestamp(filename[i+1]['timestamp']/1000.0)-datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0)
                    current=diff.total_seconds()
                else:
                    continue
            if code not in video:
                video[code]=[(filename[i]['event_type'],datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0),current,float(videoDict['speed']))]
            else:
                video[code].append((filename[i]['event_type'],datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0),current,float(videoDict['speed'])))
        else:
            if found:
                video[code].append((filename[i]['event_type'],datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0)))
                found=False
                code=''
    return video

def parseTimes(listTuples):
    '''Takes a list of 3-tuples and returns a list of intervals. If the current video time is NaN, then
    that event is ignored.'''
    intervals=[]
    type1='play_video'
    type2='pause_video'
    length=len(listTuples)
    i=0
    while i<length-1:
        if listTuples[i][0]==type1:
            start=listTuples[i][2]
            if listTuples[i+1][0]==type2:
                end=listTuples[i+1][2]
            else:
                diff=listTuples[i+1][1]-listTuples[i][1]
                end=start+(listTuples[i][3]*diff.total_seconds())
            if math.isnan(start)==False and math.isnan(end)==False:
                intervals.append([start,end])
            i+=1
        else:
            i+=1
    return intervals
    
#length=json.load(open('Video-Data/length.json'))

def parseAllVid(videoDict):
    '''Takes a dictionary generated by generateVideoDict() and returns a dictionary where the keys are
    video IDs and values are time intervals'''
    all={}
    for key in videoDict:
        try:
            vidLength=length[key]
            intervals=parseTimes(videoDict[key])
            for i in intervals:
                if i[1]>vidLength:
                    i[1]=vidLength
            all[key]=intervals
        except KeyError:
            all[key]=parseTimes(videoDict[key])
    return all

#listOfFileNames=os.listdir('examtakers')

def allUsers(listOfFiles):
    '''Takes in a list of files for each student and writes a json file with
    a dictionary of intervals for each student'''
    for i in listOfFiles:
        d=generateVideoDict('examtakers/'+i)
        combinedD=parseAllVid(d)
        with open('newData/'+i, 'w') as outfile:
            json.dump(combinedD, outfile)

#allUsers(listOfFileNames)                 

def totalTime(dirname):
    '''Takes in a folder with files about each student. Creates a json file with a dictionary
    where keys are student IDs and values are total time they spent watching videos in minutes.
    :param dirname: newData is a folder with student files.'''
    timeDict={}
    listFiles=os.listdir(dirname)
    for i in listFiles:
        oneFile=json.load(open(dirname+'/'+i))
        for key in oneFile:
            #in minutes
            total=(numpy.sum(numpy.diff(oneFile[key])))/60
            if i in timeDict:
                timeDict[i]+=total
            else:
                timeDict[i]=total
    with open('totalTime.json', 'w') as outfile:
        json.dump(timeDict, outfile)

#totalTime('newData')


def countViews(filename):
    '''Takes in a dictionary of intervals and returns a dictionary where the keys are
    current time in video (in seconds) and values are number of rewatches at that time
    :param dirname: newData is a folder with student files.'''
    data = json.load(open(filename))            
    peaksDct = {}
    for key in data.keys():
        values = data[key]
        counterSeg = Counter()
        for seg in values:
            seg = [int(floor(seg[0])), int(ceil(seg[1]))] # rounds the intervals
            end = seg[1]
            for el in range(seg[0], end+1):
                counterSeg[el] += 1
        newC=Counter({ k: v for k, v in counterSeg.iteritems() if v not in (0, 1)}) # ignore seconds with 0 or 1 views
        if len(newC) != 0:
            peaksDct[key] = newC
    return peaksDct   

       
def filterRewatches(dirname):
    '''Creates a json file of dictionaries where the keys are current time 
    in video (in seconds) and values are number of rewatches at that time.
    :param dirname: newData is a folder with student files.'''
    listFiles=os.listdir(dirname)
    for i in listFiles:
        rewatches=countViews(dirname+'/'+i)
        with open('rewatches/'+i, 'w') as outfile:
            json.dump(rewatches, outfile)
            
#filterRewatches('newData')

            
def addRewatches(dirname):
    '''Creates a json file of a dictionary where the keys are user IDs and the values
    are dictionaries with the amount of time rewatched in seconds for each video.
    :param dirname: rewatches is a folder with student files which contain rewatch view counts.'''
    rewatches={}
    listFiles=os.listdir(dirname)
    for i in listFiles:
        oneFile=json.load(open(dirname+'/'+i))
        secs={}
        for key in oneFile:
            total=sum(oneFile[key].values())-len(oneFile[key].values()) # subtract first time from rewatches
            secs[key]=total
        rewatches[i]=secs
    with open('totalRewatchTime.json', 'w') as outfile:
        json.dump(rewatches, outfile)

#addRewatches('rewatches')

def rewatchPeaks(dirname):
    '''Creates a json file of a dictionary where keys are video IDs 
    and values are total rewatch views at each second.
    :param dirname: rewatches is a folder with student files which contain rewatch view counts.'''
    rewatches={}
    listFiles=os.listdir(dirname)
    for i in listFiles:
        oneFile=json.load(open(dirname+'/'+i))
        for videoID in oneFile:
            new=Counter({k:v-1 for k,v in oneFile[videoID].items()}) # subtract 1 to exclude the 1st time
            if videoID not in rewatches:
                rewatches[videoID]=new
            else:
                rewatches[videoID]+=new
    with open('rewatchPeaks.json', 'w') as outfile:
            json.dump(rewatches, outfile)

#rewatchPeaks('rewatches')            
                                    
def getUniqueViews(dirname):
    '''Creates a dictionary where the keys are video IDs and values are unique views.
    :param dirname: newData contains student files'''
    d={}
    listFiles=os.listdir(dirname)
    for i in listFiles:
        oneFile=json.load(open(dirname+'/'+i))
        for video in oneFile:
            if video not in d:
                d[video]=1
            else:
                d[video]+=1
    with open('uniqueViews.json', 'w') as outfile:
        json.dump(d, outfile)

#getUniqueViews('newData')       
                     
def groupUniqueViews(groupFile,uniqueFile):
    '''Creates a json file that adds the number of views for multiple videos that are grouped together
       :param groupFile: videoTitles.json contains the grouped video IDs
        :param uniqueFile: uniqueViews.json contains the number of unique views for each video.'''
    uniqueViews = {}
    ids=json.load(open(groupFile))
    unique=json.load(open(uniqueFile))
    for title in ids:
        try: # only get the group views for videos with transcripts
            total=0
            videoWithTranscript = ids[title]['url'][32:] # get id of video with transcript
            for i in ids[title]['ID']:
                total += unique[i]
            uniqueViews[videoWithTranscript] = total
        except KeyError:
            pass # transcript does not exist
    with open('uniqueGroupViews.json', 'w') as outfile:
        json.dump(uniqueViews, outfile)   

#groupUniqueViews('Video-Data/videoTranscripts/videoTitles.json','Video-Data/FinishedCourseData/uniqueViews.json')


def groupVideos():
    '''Aggregates the views of the videos that are the same (but at different speeds).
    Creates a json file where the 147 keys are video IDs with transcripts and values are views
    at each second'''
    groupCounts = {}
    ids = json.load(open('Video-Data/videoTranscripts/videoTitles.json'))
    length = json.load(open('Video-Data/FinishedCourseData/lengthsAndViews.json'))
    counts = json.load(open('Video-Data/FinishedCourseData/rewatchPeaks.json'))
    for title in ids:
        try:
            videoWithTranscript = ids[title]['url'][32:] # get id of video with transcript
            temp = {}
            vidLen = ids[title]['length'] # length of video with transcript
            for i in ids[title]['ID']: # loop through list of grouped IDs
                vidLen2 = length[i]['length']
                if i != videoWithTranscript:
                    ratio = float(vidLen)/vidLen2
                    for sec in counts[i]:
                        updated = int(round(int(sec)*ratio))
                        if updated not in temp:
                            temp[updated] = counts[i][sec]
                        else:
                            temp[updated] += counts[i][sec]
                else:
                    for sec in counts[i]:
                        if int(sec) not in temp:
                            temp[int(sec)] = counts[i][sec]
                        else:
                            temp[int(sec)] += counts[i][sec]
            groupCounts[videoWithTranscript] = temp
            
        except KeyError: # transcript does not exist
            pass
            
    with open('groupPeaks.json', 'w') as outfile:
            json.dump(groupCounts, outfile)



def getRatio():
    '''Creates a dictionary where keys are seconds and views are ratios (totalView/uniqueUsers)'''
    ratioDict={}
    viewCounts=json.load(open('Video-Data/FinishedCourseData/groupPeaks.json')) # total number of rewatches in all grouped videos
    uniqueViewers=json.load(open('Video-Data/FinishedCourseData/uniqueGroupViews.json')) # number of unique users for each video
    for video in viewCounts:
        d={}
        for secs in viewCounts[video]:
            ratio=float(viewCounts[video][secs])/uniqueViewers[video]
            d[secs]=ratio
        ratioDict[video]=d
    with open('ratios.json', 'w') as outfile:
        json.dump(ratioDict, outfile)   


def getMaxRatio():
    '''Returns the maximum ratio from ratios.json()'''
    ratios=json.load(open('Video-Data/FinishedCourseData/ratios.json'))
    ratioList=[] # will store max ratio of each video
    for video in ratios:
        maxVal=max(ratios[video].values())
        if maxVal==6917.0:
            print video
        ratioList.append(maxVal)
    return max(ratioList)

def normalize():
    '''Normalizes a set of data by computing ratio/maxRatio. Creates a dictionary 
    where the keys are video IDs and values are the ratios at every second.'''
    ratioDict = {}
    ratios=json.load(open('Video-Data/FinishedCourseData/ratios.json'))
    maxRatio=getMaxRatio()
    for video in ratios:
        one={}
        for sec in ratios[video]:
            one[sec]=float(ratios[video][sec])/maxRatio
        ratioDict[video]=one
    with open('normalize.json', 'w') as outfile:
        json.dump(ratioDict, outfile)
        
def getBreaks(filename):
    '''Creates a dictionary where keys are video IDs and values are lists of tuples: 
       (when the break occurred,how long the break lasted).
       Break is defined as pause-play events.
       :param filename: one of the student files in examtakers.'''
    d={}
    events=generateVideoDict(filename)
    for vid in events:
        for i in range(len(events[vid])-1):
            if events[vid][i][0] == 'pause_video':
                if events[vid][i+1][0] == 'play_video':
                    when=events[vid][i][2] # when the break occurs in terms of video time
                    length=(events[vid][i+1][1]-events[vid][i][1]).total_seconds() # calculate difference in datetimes in seconds
                    if vid not in d:
                        d[vid] = [(when,length)]
                    else:
                        d[vid] += [(when,length)]
                        
    return d
            
def aggregateBreaks(dirname): # runtime: 25 minutes
    '''Calls getBreaks() to generate a dictionary where keys are video IDs and 
       values are lists of tuples: (when the break occurred,how long the break lasted).
       :param dirname: examtakers is a directory with student files.'''
    
    ids = json.load(open('Video-Data/videoTranscripts/videoTitles.json'))
    length = json.load(open('Video-Data/FinishedCourseData/lengthsAndViews.json'))
    
    # create dictionary with all break events   
    d={}
    listFiles=os.listdir(dirname)
    for s in listFiles: # loop through each student file
        studentDict=getBreaks(dirname+'/'+s)
        for vid in studentDict:
            if vid not in d:
                d[vid]=studentDict[vid] # append list of tuples to dict
            else:
                d[vid]+=studentDict[vid]
    
    # filter through d to group videos
    for title in ids:
        try:
            videoWithTranscript = ids[title]['url'][32:] # get id of video with transcript
            vidLen = ids[title]['length'] # length of video with transcript
            for i in ids[title]['ID']: # loop through list of grouped IDs
                if i != videoWithTranscript:
                    vidLen2 = length[i]['length']
                    ratio = float(vidLen)/vidLen2
                    for tups in d[i]:
                        updated=(tups[0]*ratio,tups[1])
                        d[videoWithTranscript].append(updated)
                    del d[i]
        except KeyError: # transcript does not exist
            for i in ids[title]['ID']:
                if i in d:
                    del d[i]
                
    with open('pausePlay.json', 'w') as outfile:
            json.dump(d, outfile)

def binning(VIDEOID,lis):
    '''Helper function for breakBins() and countBins(). 
       Returns a list that puts each element of lis into a bin.
       :param lis: list of times or counts'''
    subs=requests.get('http://video.google.com/timedtext?lang=en&v='+VIDEOID).content
    a=xmltodict.parse(subs)
    listOfSubs=a['transcript']['text']
    startTimes=[]
    for i in listOfSubs:
        startTimes.append(float(i['@start']))
    bins=[startTimes[bisect.bisect(startTimes[1:],elt)] for elt in lis]
    return bins

def breakBins(pausePlay): # runtime 1 min
    '''Creates a dictionary where keys are video IDs and values are
       dictionary of break counts at each bin interval.
       :param pausePlay: pausePlay.json is the file generated by aggregateBreaks()''' 
    d={}
    f=json.load(open(pausePlay))
    for vid in f:
        times = [x[0] for x in f[vid]] # create list of when the breaks occurred    
        bins = binning(vid,times)
        binCount = collections.Counter(bins)
        d[vid] = binCount
    with open('pausePlayBins.json', 'w') as outfile:
        json.dump(d, outfile)    
                                                                                                                                      
def countPlays(filename):
    '''Creates a dictionary where keys are video IDs and values are play count lists.
       :param filename: one of the student files in examtakers.'''
    d={}
    events=generateVideoDict(filename)
    for vid in events:
        oneVid=[] # list of when plays occur
        for i in range(len(events[vid])):
            if events[vid][i][0] == 'play_video':
                time = events[vid][i][2] # current time in video
                oneVid.append(time) 
        d[vid]=oneVid
    return d

def countPauses(filename):
    '''Creates a dictionary where keys are video IDs and values are pause count lists.
       :param filename: one of the student files in examtakers.'''
    d={}
    events=generateVideoDict(filename)
    for vid in events:
        oneVid=[] # list of when pauses occur
        for i in range(len(events[vid])):
            if events[vid][i][0] == 'pause_video':
                time = events[vid][i][2] # current time in video
                oneVid.append(time) 
        d[vid]=oneVid
    return d
    
def aggregate(dirname): #runtime 18 min
    '''Calls countPlays() or countPauses() to generate a dictionary where keys are video IDs and 
       values are lists of play/pause events.
       :param dirname: examtakers is a directory with student files.'''
    
    ids = json.load(open('Video-Data/videoTranscripts/videoTitles.json'))
    length = json.load(open('Video-Data/FinishedCourseData/lengthsAndViews.json'))
    
    # create dictionary with all pause/play events  
    d={}
    listFiles=os.listdir(dirname)
    for s in listFiles: # loop through each student file
        studentDict=countPauses(dirname+'/'+s)
        for vid in studentDict:
            if vid not in d:
                d[vid]=studentDict[vid]
            else:
                d[vid]+=studentDict[vid]
    
    # filter through d to group videos
    for title in ids:
        try:
            videoWithTranscript = ids[title]['url'][32:] # get id of video with transcript
            vidLen = ids[title]['length'] # length of video with transcript
            for i in ids[title]['ID']: # loop through list of grouped IDs
                if i != videoWithTranscript:
                    vidLen2 = length[i]['length']
                    ratio = float(vidLen)/vidLen2
                    for elt in d[i]:
                        d[videoWithTranscript].append(ratio*elt)
                    del d[i]
        except KeyError: # transcript does not exist
            for i in ids[title]['ID']:
                if i in d:
                    del d[i]
                
    with open('allPauses.json', 'w') as outfile:
        json.dump(d, outfile) 

def ppBins(allPP): 
    '''Creates a dictionary where keys are video IDs and values are
       dictionary of break counts at each bin interval.
       :param allPP: allPlays.json/allPauses is the file generated by aggregate()''' 
    d={}
    f=json.load(open(allPP))
    for vid in f:
        times = f[vid] # list of when the play/pauses occurred    
        bins = binning(vid,times)
        binCount = collections.Counter(bins)
        d[vid] = binCount
    with open('pauseBins.json', 'w') as outfile:
        json.dump(d, outfile)

#video1='CJh-mscFZgU' # Operations on Lists video
#video2='SVQuLOiHJeE' # Towers of Hanoi video

def analyzeEvents(dirname, videoID): #3:37-4:26
    ''':param dirname: examtakers is a directory with student files.''' 
    # create dictionary with all pause/play events  
    allCounts = []
    listFiles=os.listdir(dirname)
    for s in listFiles: # loop through each student file
        eventList = analyzeUser(dirname +'/' + s, videoID)
        allCounts.append(eventList)
    toOneList = [item for sublist in allCounts for item in sublist] # before it was a list of lists, but counter needs a list of strings
    d = collections.Counter(toOneList)
    with open('Video-Data/analyzeEvents.json', 'w') as outfile:
        json.dump(d, outfile)
    
def analyzeUser(fileName, videoID):
    '''analyzes the event types for one user
       :param fileName: file of one student from examtakers.
       :param videoID: video ID of the video we're analyzing'''    
    filename=json.load(open(fileName))
    eventList = []
    for i in range(len(filename)):
        try:
            d = json.loads(ast.literal_eval(filename[i]['event']))
            userEvent = dict((k,v) for (k,v) in d.items())
            if userEvent['code'] == videoID:
                
                if filename[i]['event_type']=='pause_video':
                    if filename[i+1]['event_type'] not in ['play_video','pause_video']:
                        nextEvent = filename[i+1]['event_type'] # get event_type of next event
                        eventList.append(nextEvent)
                            
                if filename[i]['event_type']=='play_video':        
                    if filename[i+1]['event_type'] not in ['play_video','pause_video']:
                        nextEvent = filename[i+1]['event_type'] # get event_type of next event
                        eventList.append(nextEvent)
                    if filename[i-1]['event_type'] not in ['play_video','pause_video']:
                        beforeEvent = filename[i-1]['event_type'] # get event_type of next event
                        eventList.append(beforeEvent)
                        
        except (KeyError, ValueError, AttributeError, TypeError,IndexError):
            pass
    return eventList
                 
def userEventList(fileName):
    '''Returns a list of events, in chronilogical order, that the student did.
       :param fileName: one of the student files in examtakers'''
    filename=json.load(open(fileName))
    eventList = []
    for i in range(len(filename)):
        try:
            e = filename[i]['event_type'] # the event type
            if 'problem' in e:
                eventList.append('problem')
            elif 'Problem_Set' in e:
                eventList.append('problem_set')
            elif 'info' in e:
                eventList.append('updates_and_news')
            elif 'courseware' in e:
                eventList.append('courseware')
            elif 'Lecture' in e:
                eventList.append('lecture')
            elif 'wiki' in e:
                eventList.append('wiki')
            elif 'discussion' in e:
                eventList.append('discussion')
            elif 'progress' in e:
                eventList.append('progress')
            elif 'goto_position' in e:
                eventList.append('navigation')
            elif e in ['seq_goto','seq_next','seq_prev']:
                eventList.append('navigation')    
            elif e == 'page_close':
                eventList.append('page_close')
            elif e == 'accordian':
                eventList.append('accordian')
            elif e == 'play_video':
                # find when in the video the play event occurred
                # and add that time in a tuple to the eventList
                d = json.loads(ast.literal_eval(filename[i]['event']))
                videoDict=dict((k,v) for (k,v) in d.items())
                try:
                    etime = float(videoDict['currentTime'])
                    if etime<0:
                        raise ValueError
                except (KeyError, TypeError, ValueError):
                    if filename[i-1]['event_type']=='pause_video':
                        etime=etime
                    elif filename[i-1]['event_type']=='play_video':
                        diff=datetime.datetime.utcfromtimestamp(filename[i+1]['timestamp']/1000.0)-datetime.datetime.utcfromtimestamp(filename[i]['timestamp']/1000.0)
                        etime=diff.total_seconds() 
                eventList.append(('play_video',etime))
            elif e == 'pause_video':
                eventList.append('pause_video')
            else:
                eventList.append('other')           
        except (KeyError, ValueError, AttributeError, TypeError):
            pass
    return eventList
        
def beforePlay(dirname, VIDEOID): #32 min 2:50
    '''Creates a dictionary where keys are bins (this depends on the transcript of the given video)
       and keys are lists of 5-tuples that show the 5 events before a play_video event.
       :param dirname: examtakers is a folder with student files.'''
    subs=requests.get('http://video.google.com/timedtext?lang=en&v='+VIDEOID).content
    a=xmltodict.parse(subs)
    listOfSubs=a['transcript']['text']
    startTimes=[]
    for i in listOfSubs:
        startTimes.append(float(i['@start']))
       
    listFiles=os.listdir(dirname)
    d={}
    for s in listFiles: # loop through each student file
        eventList = userEventList(dirname + '/' + s)
        for e in eventList:
             
            if 'play_video' in e: 
                toBin=startTimes[bisect.bisect(startTimes[1:],e[1])] # e[1] is the time the play event occurred
                if toBin != 0.0:
                    eindex = eventList.index(e)
                    # get up to 5 previous events leading up to play event
                    if eindex in [1,2,3,4,5]:
                        previous = eventList[0:eindex]
                    elif eindex > 5:
                        previous = eventList[eindex-5:eindex]
                    previous=[i[0] if type(i)==tuple else i for i in previous]
                    if toBin not in d:
                        d[toBin] = [previous]
                    else:  
                        d[toBin].append(previous)
    with open('beforePlay_CJh-mscFZgU.json', 'w') as outfile:
        json.dump(d, outfile)                                                                                    
                                                                                                                                        
def percentViews():
    '''Returns a dictionary where keys are video IDs and values are 
       percentage of unique students who watched the video. There are 147 videos.'''
    views=json.load(open('FinishedCourseData/uniqueViews.json'))
    ids=json.load(open('videoTranscripts/videoTitles.json'))
    d={}
    for title in ids:
        try: # only get the group views for videos with transcripts
            total=0
            videoWithTranscript = ids[title]['url'][32:] # get id of video with transcript
            for i in ids[title]['ID']:
                total += views[i]
            percent = float(total)/6290 # 6290 is the total number of students
            d[videoWithTranscript] = percent
        except:
            pass               
    with open('percentViews.json', 'w') as outfile:
        json.dump(d, outfile)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  


#TESTING
                                
#print analyzeUser('examtakers/_aziunojslooran.json','pGd3WqZK4Cg')
#analyzeEvents('examtakers','CJh-mscFZgU')
#print userEventList('examtakers/_aziunojslooran.json')    